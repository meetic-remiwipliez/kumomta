# Default values for kumomta.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

kumoConfigFiles: []

replicaCount: 1

image:
  repository: ghcr.io/kumocorp/kumomta
  pullPolicy: IfNotPresent
  tag: 2025.03.19-1d3f1f67

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

deployment:
  args:
    - --policy=/opt/kumomta/etc/policy/init.lua
    - --user=kumod
  command:
    - /opt/kumomta/sbin/kumod

env:
  # Enable debug logging for all KumoMTA components
  # Format: component=level,component=level
  # Available levels: trace, debug, info, warn, error
  # Available components: kumod, lua, http, smtp, queue, etc.
  - name: KUMOD_LOG
    value: "kumod=debug,lua=debug,http=debug,smtp=debug,queue=debug,egress=debug,dns=debug"
  # Enable sink mode by default for safe testing
  # All emails will be redirected to the sink service instead of being sent
  # Set to "false" to disable sink mode and send real emails
  - name: KUMOMTA_SINK_ENABLED
    value: "true"
  # Sink endpoint: adjust the service name and namespace according to your Helm release
  # Service name format: {{ release-name }}-kumomta-sink.{{ namespace }}.svc.cluster.local
  # Default uses the same namespace as the release (will be set by template if needed)
  - name: KUMOMTA_SINK_ENDPOINT
    value: "kumomta-sink.kumomta.svc.cluster.local"
  # Sink IP: ClusterIP of the sink service (use [IP] format to avoid DNS/MX resolution)
  # Get it with: kubectl get svc -n kumomta kumomta-sink -o jsonpath='{.spec.clusterIP}'
  # If not set, will try to use KUMOMTA_SINK_SERVICE_HOST (Kubernetes auto-injected env var)
  # Note: Using IP directly avoids DNS resolution issues in Kubernetes
  - name: KUMOMTA_SINK_IP
    value: "" # Will be auto-populated from KUMOMTA_SINK_SERVICE_HOST if available
  # StirTalk egress source IPs (optional)
  # If not set, KumoMTA will use the Pod IP (default behavior in Kubernetes)
  # See: https://kumomta.com/blog/moving-from-momentum
  # These correspond to Momentum bindings StirTalk3 and StirTalk5
  # Only set these if you have specific IPs configured at the network level
  - name: KUMOMTA_STIRTALK_3_IP
    value: ""
  - name: KUMOMTA_STIRTALK_5_IP
    value: ""
  # Redis/Dragonfly configuration for shared throttles
  # Using Dragonfly in namespace dragonflydb, service name dragonflydb
  # Format: redis://[username:password@]host:port[/database]
  # Dragonfly uses Redis protocol, default port is 6379
  - name: KUMOMTA_REDIS_HOST
    value: "redis://dragonflydb.dragonflydb.svc.cluster.local:6379"
  # Optional: Redis cluster mode (set to "true" if using Redis Cluster)
  # Dragonfly is single-node compatible, so leave as default (false)
  # - name: KUMOMTA_REDIS_CLUSTER_MODE
  #   value: "false"
  # Optional: Redis pool size (default: 100)
  # - name: KUMOMTA_REDIS_POOL_SIZE
  #   value: "100"
  # Optional: Read from replicas (default: true)
  # - name: KUMOMTA_REDIS_READ_FROM_REPLICAS
  #   value: "true"
  # Optional: Redis authentication (if enabled on Dragonfly)
  # - name: KUMOMTA_REDIS_USERNAME
  #   value: ""
  # - name: KUMOMTA_REDIS_PASSWORD
  #   value: ""
  - name: KUMOMTA_TRUSTED_HOSTS
    value: "127.0.0.1,0.0.0.0/0"  # localhost + toutes les IPs

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext:
  runAsUser: 999
  fsGroup: 999
  sysctls:
    - name: net.ipv4.ip_local_port_range
      value: "5000 63000"
  # fsGroup: 2000

securityContext:
  {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  httpPort: 8000
  metricsPort: 8080
  smtpPort: 2500

serviceMonitor:
  enabled: true
  # Port used for metrics endpoint (use port name "http" or port number)
  # Defaults to "http" (port name) which is more robust
  targetPort: "http"
  # Additional labels for ServiceMonitor (e.g., for Prometheus discovery)
  labels:
    release: prometheus-lab
  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/basic-auth.md
  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#monitoring.coreos.com/v1.BasicAuth
  # basicAuth: {}
  # basicAuth:
  #   username:
  #     name: foo # name of secret
  #     key: username # key in secret
  #   password:
  #     name: foo # name of secret
  #     key: username # key in secret

ingress:
  enabled: false
  className: "nginx-internal"
  annotations:
    {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# livenessProbe:
# httpGet:
#   path: /
#   port: http
readinessProbe:
  httpGet:
    path: /api/check-liveness/v1
    port: http

lifecycleHook:
  preStop:
    exec:
      command:
        - /bin/sh
        - -c
        - sleep 15

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  # additionalMetrics: []

# Additional volumes on the output StatefulSet definition.
volumes:
  - name: kumo-configs
    configMap:
      name: kumo-configs
  - name: http-listener-keys
    secret:
      secretName: http-listener-keys
      optional: false
  - name: dkim-keys-talk-stir-com
    secret:
      secretName: dkim-keys-talk-stir-com
      optional: true
  - name: kumo-logs
    emptyDir: {}
  # Use emptyDir instead of PVC for spool storage (data is ephemeral)
  # Set to false to use PersistentVolumeClaim instead
  - name: spool
    emptyDir: {}

# Additional volumeMounts on the output StatefulSet definition.
volumeMounts:
  - name: kumo-configs
    mountPath: "/opt/kumomta/etc/policy"
    readOnly: true
  - name: http-listener-keys
    mountPath: "/opt/kumomta/etc/http_listener_keys/"
    readOnly: true
  - name: dkim-keys-talk-stir-com
    mountPath: "/opt/kumomta/etc/policy/dkim"
    readOnly: true
  - name: kumo-logs
    mountPath: "/var/log/kumomta"
  - name: spool
    mountPath: "/var/spool/kumomta"

# PersistentVolumeClaim templates - DISABLED by default
# Uncomment and configure to use persistent storage instead of emptyDir
# volumeClaimTemplates:
#   - metadata:
#       name: spool
#     spec:
#       accessModes: ["ReadWriteOnce"]
#       resources:
#         requests:
#           storage: 25Gi

tolerations: []

affinity: {}

topologySpreadConstraints: []

tsa:
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
    # additionalMetrics: []
  env:
    # TSA Trusted Hosts: IPs/CIDRs allowed to access TSA HTTP endpoints without auth
    # For Kubernetes, allow connections from all pods in the cluster
    # Format: comma-separated list of IPs or CIDR blocks
    - name: KUMOMTA_TSA_TRUSTED_HOSTS
      value: "0.0.0.0/0,::/0"
  deployment:
    command:
      - /opt/kumomta/sbin/tsa-daemon
      - --policy
      - /opt/kumomta/etc/policy/tsa_init.lua
    # args: []
  # livenessProbe:
  # httpGet:
  #   path: /
  #   port: http
  readinessProbe:
    httpGet:
      path: /get_config_v1/shaping.toml
      port: http
  lifecycleHook:
    preStop:
      exec:
        command:
          - /bin/sh
          - -c
          - sleep 15
  podLabels: {}
  ingress:
    enabled: false
    className: "nginx-internal"
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local
    # Additional volumes on the TSA deployment definition.
  # PersistentVolumeClaim templates - DISABLED by default
  # Uncomment and configure to use persistent storage instead of emptyDir
  # volumeClaimTemplates:
  #   - metadata:
  #       name: tsa-spool
  #     spec:
  #       accessModes: ["ReadWriteOnce"]
  #       resources:
  #         requests:
  #           storage: 5Gi
  volumes:
    - name: kumo-configs
      configMap:
        name: kumo-configs
    - name: http-listener-keys
      secret:
        secretName: http-listener-keys
        optional: false
    - name: kumo-logs
      emptyDir: {}
    # Use emptyDir instead of PVC for TSA spool storage (data is ephemeral)
    - name: tsa-spool
      emptyDir: {}

  # Additional volumeMounts on the TSA deployment definition.
  volumeMounts:
    - name: kumo-configs
      mountPath: "/opt/kumomta/etc/policy"
      readOnly: true
    - name: http-listener-keys
      mountPath: "/opt/kumomta/etc/http_listener_keys/"
      readOnly: true
    - name: kumo-logs
      mountPath: "/var/log/kumo"
    - name: tsa-spool
      mountPath: "/var/spool/kumomta"
  service:
    type: ClusterIP
    httpPort: 8008

  tolerations: []

  affinity: {}

sink:
  enabled: true
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
    # additionalMetrics: []
  deployment:
    command:
      - /opt/kumomta/sbin/kumod
      - --policy
      - /opt/kumomta/etc/policy/sink.lua
    # args: []
  # livenessProbe:
  # httpGet:
  #   path: /
  #   port: http
  # readinessProbe:
  lifecycleHook:
    preStop:
      exec:
        command:
          - /bin/sh
          - -c
          - sleep 15

  podLabels: {}

  service:
    type: ClusterIP
    httpPort: 8008
    smtpPort: 25

  ingress:
    enabled: false
    className: "nginx-internal"
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local
    # Additional volumes on the TSA deployment definition.
    #
  volumes:
    - name: sink-configs
      configMap:
        name: sink-configs
    - name: kumo-logs
      emptyDir: {}
  volumeMounts:
    - name: sink-configs
      mountPath: "/opt/kumomta/etc/policy"
      readOnly: true
    - name: kumo-logs
      mountPath: "/var/log/kumo"

# HTTP Listener Keys Secret configuration
# This secret stores username/password pairs for HTTP API authentication
# Each key in the secret is a username, and the value is the password (base64 encoded)
httpListenerKeys:
  enabled: true
  secretName: http-listener-keys
  # Users configuration: username -> password (plain text, will be base64 encoded)
  # Generate passwords using: openssl rand -hex 16
  users:
    # Default user for testing (password: "default-password")
    # Change this in production!
    user1: "default-password"
    # Add more users as needed:
    # admin: "your-secure-password-here"
    # api-user: "another-secure-password"

# DKIM Keys Secret configuration (per domain/binding group)
# Each domain/binding group has its own secret configuration
dkimKeys:
  # StirTalk binding group - talk.stir.com domain
  talkStirCom:
    enabled: true
    secretName: dkim-keys-talk-stir-com
    # Private key content (plain text, will be base64 encoded by Helm)
    # This key is loaded from configuration_momentum/global/dk/talk.stir.com/052024s2048.key
    # IMPORTANT: The key filename in the secret must match the filename specified in dkim_talk.stir.com.toml
    privateKey: |
      -----BEGIN RSA PRIVATE KEY-----
      MIIEpAIBAAKCAQEA1IZBuNnVSGgRB0TGOW+sLoaRzqyU/BahOB8Gj7Cc3+9b3jNv
      5CGxJrZWBMWj8vl04zXo9xJ89vDObhpNdwC48WPhUgA9IeHZsgpGjQPBbqD70uvt
      4QwkGGvBEFVhqPpXd8s56XT8HQckmKSWSCccn3t4izjlBBsarLLbXmJFSHs5xWGa
      OPwj52coPP+qdyjB2I3wZx0FRMN6R9l9rgCs3GtCadgv08LsJLsu4sy+fzYWdP6d
      D08rgHSUlJ72feV/vdtKN3PL4vGb+CrMDGVifeNOl5NFlB/zM7keM73hIaEcpPs7
      /b7nJ/6PgYHcoz98XWOPI+vxAPzZXacZAwEH2QIDAQABAoIBAQDDPyjIG5BfugPS
      6rM190t3Xvg7qMAjLOMmfRJ5Fie5b9y1sgncy7tFtoQmVDEAO3/Qcim6O4kFEUyF
      SLLcXpSKaFmMDV4cb7KhZ+FTEh02dr2EFG5xr8bFjNFNITPcm0maa+Gjgm9Qd8x+
      U88hMJWSS0v+k+GKuR/zg0oYVy4RnD6pnvcdi18FjfcyPLh9QHy1lriTBo5kYYCB
      FRWaV9Do0kEr2vEcL4z3Nn4xLCZ3sa+ybeAkgEEtLRI+dJMer8Bnba6yYzjVVI8V
      ZckZNLXyXiKzswQQuGFHIVm+vxxN6+q1/i/ckPY/+B6hatpXzNcy5SmloYWdxVxk
      N8PiTvURAoGBAPeTGlsxwdcIQ12xB3N3PMS3lED5S7r2mztdEIkplcXSz0O7Sl+e
      3ce7VXV3cRjSCxwaB22vDxAEssivwCJTbIM4q0V65zbI0swVdzKdvuXJUuBP7X89
      26FcXEKRzoCBOxY+THWpOtichqUMhDrCKyV0A+JEqFc8hz7gDj6JyT41AoGBANvB
      yvPr2RRFcIRaHNiCxL+iRtWiCuNsZIIAHBsUbALazvhrHEwiipB1/DMz08oFn3KH
      gFbI6qrtLJnuttibpRG7ZOTgh1jy3H58+w/7hg2mmLNJx2huffdjrPEyk0gzEulJ
      /dsJqI43L8JhhyfHt2KrS4twzwJr3ikBkMZChueVAoGBAKML3Sq7/TX5uiwE/6w6
      lenUIS4dQJOz/427/7zlhz7OVDP+L8ADp3n31RNUg0ZeZnSua7//r4LUJU5n+Lhi
      iq9s7dcHVyjMX4+Kf4L1Qpig2xThbr8C5RdC9Xvd/MrC0UAX7VD8D8ZCZ6ZhNOBh
      qfqzii9FGjzBnyx4cMkdA00VAoGALfZDR279kRLQ7K2YOORo2BfNruLcWiKShuoU
      9sj3qkUvYp+sZHQY/QvgOqlNU4SHi8GxYvVUt3kxieR2k6lCBgpmmMQpKr5oxX/I
      VthpejNs3prAvSPW7sYHJs9IJKKiAu75zDUh7tS2BXa2eOh5f4aKH1jxwvTimzr7
      l6vUYV0CgYBd20PQKIOX6wVHNnjBnrZH8BBsgILbK64Oi0R+e+oyM13lmSdN6ayE
      Xlz+qSDyRL9ez93oqoD/iJxk4dh+2BRxvQ5TkvjDQ+NljAVIPdGavAHKupVhb9MT
      wTidA6v6pTLrSCY3dHPTIsesTYhuy45WEL4ZqAYtVh34K4lPPpmAHg==
      -----END RSA PRIVATE KEY-----

## Debug pod with network tools (ping, curl, netcat, etc.)
## Useful for debugging network connectivity issues
debug:
  enabled: true
  image:
    repository: nicolaka/netshoot
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "64Mi"
      cpu: "100m"
    limits:
      memory: "128Mi"
      cpu: "200m"

## Extra manifests to deploy as an array
extraManifests:
  []
  # - apiVersion: v1
  #   kind: ConfigMap
  #   metadata:
  #     labels:
  #       name: prometheus-extra
  #   data:
  #     extra-data: "value"
